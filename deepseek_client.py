# deepseek_client.py
# Module ch√≠nh ƒë·ªÉ giao ti·∫øp v·ªõi DeepSeek AI

import requests
import json
from typing import List, Dict, Optional
from config import OLLAMA_URL, MODEL_NAME, SCENARIOS

class DeepSeekClient:
    """Client ƒë·ªÉ t∆∞∆°ng t√°c v·ªõi DeepSeek AI qua Ollama"""
    
    def __init__(self, model_name: str = MODEL_NAME):
        self.model_name = model_name
        self.ollama_url = OLLAMA_URL
        self.conversation_history = []
        
    def check_connection(self) -> bool:
        """Ki·ªÉm tra k·∫øt n·ªëi v·ªõi Ollama"""
        try:
            response = requests.get("http://localhost:11434/api/tags")
            return response.status_code == 200
        except requests.exceptions.ConnectionError:
            return False
    
    def list_models(self) -> List[str]:
        """L·∫•y danh s√°ch models ƒë√£ c√†i"""
        try:
            response = requests.get("http://localhost:11434/api/tags")
            if response.status_code == 200:
                models = response.json().get('models', [])
                return [model['name'] for model in models]
            return []
        except Exception as e:
            print(f"L·ªói khi l·∫•y danh s√°ch models: {e}")
            return []
    
    def chat(
        self, 
        user_message: str, 
        scenario: str = "default",
        use_history: bool = False,
        temperature: Optional[float] = None
    ) -> str:
        """
        G·ª≠i tin nh·∫Øn v√† nh·∫≠n ph·∫£n h·ªìi
        
        Args:
            user_message: C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
            scenario: K·ªãch b·∫£n s·ª≠ d·ª•ng (t·ª´ SCENARIOS)
            use_history: C√≥ s·ª≠ d·ª•ng l·ªãch s·ª≠ chat kh√¥ng
            temperature: ƒê·ªô s√°ng t·∫°o (0.0-1.0), None = d√πng m·∫∑c ƒë·ªãnh
            
        Returns:
            C√¢u tr·∫£ l·ªùi t·ª´ AI
        """
        if scenario not in SCENARIOS:
            scenario = "default"
        
        scenario_config = SCENARIOS[scenario]
        system_prompt = scenario_config["system_prompt"]
        temp = temperature if temperature is not None else scenario_config.get("temperature", 0.7)
        
        # T·∫°o messages
        messages = []
        
        # Th√™m system prompt
        messages.append({
            "role": "system",
            "content": system_prompt
        })
        
        # Th√™m l·ªãch s·ª≠ h·ªôi tho·∫°i n·∫øu c·∫ßn
        if use_history:
            messages.extend(self.conversation_history)
        
        # Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        try:
            # G·ª≠i request
            payload = {
                "model": self.model_name,
                "messages": messages,
                "stream": False,
                "options": {
                    "temperature": temp
                }
            }
            
            response = requests.post(self.ollama_url, json=payload, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                ai_response = result['message']['content']
                
                # L∆∞u v√†o l·ªãch s·ª≠
                if use_history:
                    self.conversation_history.append({
                        "role": "user",
                        "content": user_message
                    })
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": ai_response
                    })
                
                return ai_response
            else:
                return f"L·ªói: {response.status_code} - {response.text}"
                
        except requests.exceptions.Timeout:
            return "L·ªói: Timeout - AI m·∫•t qu√° nhi·ªÅu th·ªùi gian ƒë·ªÉ ph·∫£n h·ªìi"
        except requests.exceptions.ConnectionError:
            return "L·ªói: Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi Ollama. B·∫°n ƒë√£ ch·∫°y 'ollama serve' ch∆∞a?"
        except Exception as e:
            return f"L·ªói: {str(e)}"
    
    def chat_stream(
        self,
        user_message: str,
        scenario: str = "default",
        temperature: Optional[float] = None
    ):
        """
        Chat v·ªõi streaming response (tr·∫£ v·ªÅ t·ª´ng ph·∫ßn)
        """
        if scenario not in SCENARIOS:
            scenario = "default"
        
        scenario_config = SCENARIOS[scenario]
        system_prompt = scenario_config["system_prompt"]
        temp = temperature if temperature is not None else scenario_config.get("temperature", 0.7)
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]
        
        try:
            payload = {
                "model": self.model_name,
                "messages": messages,
                "stream": True,
                "options": {
                    "temperature": temp
                }
            }
            
            response = requests.post(
                self.ollama_url, 
                json=payload, 
                stream=True,
                timeout=60
            )
            
            for line in response.iter_lines():
                if line:
                    data = json.loads(line)
                    if 'message' in data:
                        yield data['message']['content']
                        
        except Exception as e:
            yield f"L·ªói: {str(e)}"
    
    def clear_history(self):
        """X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i"""
        self.conversation_history = []
    
    def get_history(self) -> List[Dict]:
        """L·∫•y l·ªãch s·ª≠ h·ªôi tho·∫°i"""
        return self.conversation_history
    
    def export_conversation(self, filename: str = "conversation.json"):
        """Xu·∫•t h·ªôi tho·∫°i ra file JSON"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.conversation_history, f, ensure_ascii=False, indent=2)
        return filename


class ScenarioManager:
    """Qu·∫£n l√Ω c√°c k·ªãch b·∫£n custom"""
    
    @staticmethod
    def list_scenarios() -> Dict:
        """L·∫•y danh s√°ch t·∫•t c·∫£ k·ªãch b·∫£n"""
        return {
            key: {
                "name": value["name"],
                "temperature": value.get("temperature", 0.7)
            }
            for key, value in SCENARIOS.items()
        }
    
    @staticmethod
    def get_scenario(scenario_name: str) -> Optional[Dict]:
        """L·∫•y th√¥ng tin chi ti·∫øt c·ªßa m·ªôt k·ªãch b·∫£n"""
        return SCENARIOS.get(scenario_name)
    
    @staticmethod
    def add_scenario(
        key: str,
        name: str,
        system_prompt: str,
        temperature: float = 0.7
    ):
        """Th√™m k·ªãch b·∫£n m·ªõi"""
        SCENARIOS[key] = {
            "name": name,
            "system_prompt": system_prompt,
            "temperature": temperature
        }


# V√≠ d·ª• s·ª≠ d·ª•ng
if __name__ == "__main__":
    # Kh·ªüi t·∫°o client
    client = DeepSeekClient()
    
    # Ki·ªÉm tra k·∫øt n·ªëi
    print("üîç Ki·ªÉm tra k·∫øt n·ªëi Ollama...")
    if client.check_connection():
        print("‚úÖ K·∫øt n·ªëi th√†nh c√¥ng!")
        
        # Li·ªát k√™ models
        models = client.list_models()
        print(f"\nüì¶ Models ƒë√£ c√†i: {models}")
    else:
        print("‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi. H√£y ch·∫°y: ollama serve")
        exit(1)
    
    # Test chat v·ªõi k·ªãch b·∫£n kh√°c nhau
    print("\n" + "="*50)
    print("TEST CHAT V·ªöI C√ÅC K·ªäCH B·∫¢N")
    print("="*50)
    
    # Test 1: Default
    print("\n1Ô∏è‚É£  K·ªãch b·∫£n: DEFAULT")
    response = client.chat("Xin ch√†o, b·∫°n l√† ai?", scenario="default")
    print(f"AI: {response}")
    
    # Test 2: Customer Support
    print("\n2Ô∏è‚É£  K·ªãch b·∫£n: CUSTOMER SUPPORT")
    response = client.chat("T√¥i qu√™n m·∫≠t kh·∫©u", scenario="customer_support")
    print(f"AI: {response}")
    
    # Test 3: Teacher
    print("\n3Ô∏è‚É£  K·ªãch b·∫£n: TEACHER")
    response = client.chat("Gi·∫£i th√≠ch cho t√¥i v·ªÅ bi·∫øn trong Python", scenario="teacher")
    print(f"AI: {response}")
    
    # Test 4: Chat v·ªõi l·ªãch s·ª≠
    print("\n4Ô∏è‚É£  Chat v·ªõi l·ªãch s·ª≠:")
    client.clear_history()
    response1 = client.chat("T√™n t√¥i l√† Minh", use_history=True)
    print(f"AI: {response1}")
    
    response2 = client.chat("T√™n t√¥i l√† g√¨?", use_history=True)
    print(f"AI: {response2}")
